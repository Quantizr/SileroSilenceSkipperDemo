<!DOCTYPE html>
<html>
  <head>
    <title>Video with Speed Adjustment Based on Real-Time Voice Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web/dist/bundle.min.js"></script>
  </head>
  <body>
    <p>SileroVAD takes around 10 seconds to load, if you start the video before that, video speed won't be adjusted until it loads.</p>
    <video id="video" width="640" height="360" controls crossOrigin="anonymous">
      <source src="https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/GoogleIO-2014-CastingToTheFuture.mp4" type="video/mp4">
    </video>
    <div id="playbackSpeed"></div>
    <br>
    <label for="playbackFast">Playback Fast:</label>
    <input type="range" min="0" max="10" step="0.1" value="3" id="playbackFast">
    <div id="playbackFastSetting"></div>
    <br>
    <label for="playbackSlow">Playback Slow:</label>
    <input type="range" min="0" max="5" step="0.1" value="1" id="playbackSlow">
    <div id="playbackSlowSetting"></div>
    <br>
    <label for="positiveSpeechThreshold">Positive Speech Threshold:</label>
    <input type="range" min="0" max="1" step="0.05" value="0.6" id="positiveSpeechThreshold">
    <div id="positiveSpeechThresholdSetting"></div>
    <br>
    <label for="negativeSpeechThreshold">Negative Speech Threshold:</label>
    <input type="range" min="0" max="1" step="0.05" value="0.4" id="negativeSpeechThreshold">
    <div id="negativeSpeechThresholdSetting"></div>
    <br>
    <label for="noSpeakingSampleThreshold">No speaking samples (at base speed):</label>
    <input type="range" min="1" max="10" step="1" value="4" id="noSpeakingSampleThreshold">
    <div id="noSpeakingSampleThresholdSetting"></div>
    <script>
      window.onload = function() {
        //ADJUSTABLE
        let playbackFast = 3.0;
        let playbackSlow = 1.5;
        let positiveSpeechThreshold = 0.6;
        let negativeSpeechThreshold = 0.4;
        let noSpeakingSampleThreshold = 4;
        //
        let playbackSpeed = 1.0;

        const playbackFastSlider = document.getElementById('playbackFast');
        const playbackSlowSlider = document.getElementById('playbackSlow');
        const positiveSpeechThresholdSlider = document.getElementById('positiveSpeechThreshold');
        const negativeSpeechThresholdSlider = document.getElementById('negativeSpeechThreshold');
        const playbackSpeedDisplay = document.getElementById('playbackSpeed');
        const noSpeakingSampleThresholdSlider = document.getElementById('noSpeakingSampleThreshold');

        playbackFastSlider.addEventListener('input', (e) => {
          playbackFast = e.target.value;
          playbackFastSetting.textContent = playbackFast;
        });

        playbackSlowSlider.addEventListener('input', (e) => {
          playbackSlow = e.target.value;
          playbackSlowSetting.textContent = playbackSlow;
        });

        positiveSpeechThresholdSlider.addEventListener('input', (e) => {
          positiveSpeechThreshold = e.target.value;
          positiveSpeechThresholdSetting.textContent = positiveSpeechThreshold;
        });

        negativeSpeechThresholdSlider.addEventListener('input', (e) => {
          negativeSpeechThreshold = e.target.value;
          negativeSpeechThresholdSetting.textContent = negativeSpeechThreshold;
        });

        noSpeakingSampleThresholdSlider.addEventListener('input', (e) => {
          noSpeakingSampleThreshold = e.target.value;
          noSpeakingSampleThresholdSetting.textContent = noSpeakingSampleThreshold;
        });

        playbackSpeedDisplay.textContent = `Playback Speed: ${playbackSpeed}`;
        playbackFastSetting.textContent = playbackFast;
        playbackSlowSetting.textContent = playbackSlow;
        positiveSpeechThresholdSetting.textContent = positiveSpeechThreshold;
        negativeSpeechThresholdSetting.textContent = negativeSpeechThreshold;
        noSpeakingSampleThresholdSetting.textContent = noSpeakingSampleThreshold;
        

        const video = document.getElementById("video");

        let audioCtx = new (window.AudioContext || window.webkitAudioContext)({});
        let source;
        let audioNodeVAD;
        let noSpeakingSamples = 0;
        let desyncCounter = 0;

        let vadStarted = false;
        let fastTime = null;
        let timeSaved = 0;

        async function startVAD() {
          if (vadStarted) return;
          audioNodeVAD = await vad.AudioNodeVAD.new(audioCtx, {
            frameSamples: 512, //32ms @ 16KHz, sample rate is resampled to 16KHz
            positiveSpeechThreshold: 1, //prevent default threshold from loading
            negativeSpeechThreshold: 0, //prevent default threshold from loading
            onFrameProcessed: (probabilities) => {
              //console.log("Frame processed", probabilities, video.currentTime);
              if (probabilities.isSpeech > positiveSpeechThreshold) {
                if (playbackSpeed != playbackSlow) {
                  playbackSpeed = playbackSlow;
                  video.playbackRate = playbackSpeed;
                  playbackSpeedDisplay.textContent = `Playback Speed: ${playbackSpeed}`;
                  noSpeakingSamples = 0
                  const currentTime = video.currentTime;
                  if (fastTime !== null) {
                    const timeDiff = Math.round((currentTime - fastTime)*1000);
                    console.log(`Sped up video time: ${timeDiff}ms`);
                    timeSaved += Math.round(timeDiff/playbackSlow);
                  }
                  console.log("Speech started - slowing down - time saved ", timeSaved/1000);
                } else {
                  if (noSpeakingSamples > 0) noSpeakingSamples--;
                }
              }

              if (probabilities.isSpeech < negativeSpeechThreshold && playbackSpeed != playbackFast) {
                noSpeakingSamples++;
                if (noSpeakingSamples >= Math.round(noSpeakingSampleThreshold/playbackSlow)) { //dynamically adjust silence gap based on video speed
                  playbackSpeed = playbackFast;
                  video.playbackRate = playbackSpeed;
                  playbackSpeedDisplay.textContent = `Playback Speed: ${playbackSpeed}`;
                  console.log("End of speech - speeding up");
                  desyncCounter++;
                  if (desyncCounter >= 10) {
                    video.currentTime += 1e-9;
                    desyncCounter = 0;
                    console.log("Resync video/audio");
                  }
                  fastTime = video.currentTime;
                }
              }
            }
          });
        }

        startVAD().then(() => {
          vadStarted = true;
          if (!video.paused && !source) {
            audioCtx.resume();

            source = new MediaStreamAudioSourceNode(audioCtx, {
              mediaStream: video.captureStream(),
            })
            const merger = audioCtx.createChannelMerger(1);
            source.connect(merger);
            audioNodeVAD.receive(merger);
            audioNodeVAD.start();
          }
        });

        video.addEventListener("play", function() {
          fastTime = null;
          if (vadStarted && !source) { //is this even possible
            audioCtx.resume();
            source = new MediaStreamAudioSourceNode(audioCtx, {
              mediaStream: video.captureStream(),
            })
            const merger = audioCtx.createChannelMerger(1);
            source.connect(merger);
            audioNodeVAD.receive(merger);
          }
          audioNodeVAD.start();
        });

        video.addEventListener("pause", () => {
          fastTime = null;
          audioNodeVAD.pause();
        });

        video.addEventListener("seeked", () => {
          fastTime = null;
        });

        video.addEventListener("loadeddata", () => {
          fastTime = null;
          if (vadStarted) {
            audioCtx.resume();
            source = new MediaStreamAudioSourceNode(audioCtx, {
              mediaStream: video.captureStream(),
            })
            const merger = audioCtx.createChannelMerger(1);
            source.connect(merger);
            audioNodeVAD.receive(merger);
          }
        });
      };
    </script>
  </body>
</html>
